{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#Import config file. Update config.py according to your environment\n",
    "import config\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from Rakuten_preprocessing import Rakuten_img_path\n",
    "\n",
    "from src.image.classifiers import ImgClassifier\n",
    "\n",
    "from src.utils.batch import fit_save_all\n",
    "from src.utils.load import load_batch_results\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(config.path_to_data, 'df_train_index.csv'))\n",
    "data_train['testset'] = False\n",
    "data_test = pd.read_csv(os.path.join(config.path_to_data, 'df_test_index.csv'))\n",
    "data_test['testset'] = True\n",
    "data = pd.concat([data_train, data_test], axis=0)\n",
    "\n",
    "#merging text into token column\n",
    "colnames = ['designation_translated', 'description_translated'] #['designation', 'description']#\n",
    "data['tokens'] = data[colnames].apply(lambda row: ' '.join(s.lower() for s in row if isinstance(s, str)), axis=1)\n",
    "\n",
    "#path to images into img_path column\n",
    "data['img_path'] = Rakuten_img_path(img_folder=config.path_to_images,\n",
    "                             imageid=data['imageid'], productid=data['productid'], suffix='_resized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels of encoded classes\n",
    "class_labels = data.groupby('prdtypedesignation')['prdtypeindex'].first().reset_index()\n",
    "class_labels.index = class_labels['prdtypeindex']\n",
    "class_labels = class_labels.drop(columns='prdtypeindex').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_train = data.loc[~data['testset'], 'img_path']\n",
    "Img_test = data.loc[data['testset'], 'img_path']\n",
    "\n",
    "Txt_train = data.loc[~data['testset'], 'tokens']\n",
    "Txt_test = data.loc[data['testset'], 'tokens']\n",
    "\n",
    "y_train = data.loc[~data['testset'],'prdtypeindex']\n",
    "y_test = data.loc[data['testset'],'prdtypeindex']\n",
    "\n",
    "#To be fed into any of our sklearn classifiers, X_train and X_test\n",
    "#should be dataframes with columns tokens and img_path\n",
    "X_train = pd.DataFrame({'tokens': Txt_train, 'img_path': Img_train})\n",
    "X_test = pd.DataFrame({'tokens': Txt_test, 'img_path': Img_test})\n",
    "\n",
    "#All data for cross-validated scores\n",
    "X = pd.concat([X_train, X_test], axis=0)\n",
    "y = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "#Number of classes\n",
    "num_classes = len(np.unique(data['prdtypeindex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage: how to train TFbertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining callbacks\n",
    "callbacks = []\n",
    "callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1, }))\n",
    "\n",
    "clf_cnn = ImgClassifier(base_name='ResNet152', img_size=(224, 224, 3), num_class=num_classes, drop_rate=0.2, epochs=5, batch_size=32, \n",
    "                    validation_data=(X_test, y_test), learning_rate=5e-5, callbacks=callbacks)\n",
    "\n",
    "clf_cnn.fit(X_train, y_train)\n",
    "clf_cnn.classification_score(X_test, y_test)\n",
    "\n",
    "clf_cnn.save('image/my_resnet152_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and ViT benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the summary csv file to save results to\n",
    "result_file_name = 'results_benchmark_img.csv'\n",
    "\n",
    "#type of modality\n",
    "modality = 'image'\n",
    "\n",
    "#Type of classifier\n",
    "class_type = 'ImgClassifier'\n",
    "\n",
    "#training parameters (or list of parameters for gridsearchCV)\n",
    "num_class = num_classes\n",
    "img_size = (224, 224, 3)\n",
    "n_epochs = 8\n",
    "batch_size = 32\n",
    "drop_rate = 0.2\n",
    "lr0 = 5e-5\n",
    "lr_min = 1e-6\n",
    "lr_decay_rate = 0.8\n",
    "\n",
    "#defining callbacks\n",
    "callbacks = []\n",
    "#adding earlystopping callback\n",
    "callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1}))\n",
    "#Adding tensorboard callback as the last one\n",
    "callbacks.append(('TensorBoard', {'log_dir': np.nan, 'histogram_freq': 1, 'update_freq': 'epoch'}))\n",
    "\n",
    "#grid search number of folds\n",
    "nfolds_grid = 0\n",
    "\n",
    "#cross-validation of f1-score\n",
    "nfolds_cv = 0\n",
    "\n",
    "#network to test\n",
    "base_name_list = ['vit_b16', 'ResNet101', 'ResNet50', 'EfficientNetB1', 'VGG16', 'ResNet152']\n",
    "\n",
    "#Initializing the list of parameters to batch over\n",
    "params_list = []\n",
    "\n",
    "for base_name in base_name_list:\n",
    "  #Adjusting tensorboard log directory\n",
    "  log_dir = os.path.join(config.path_to_tflogs, base_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  callbacks[-1][1]['log_dir'] = log_dir\n",
    "  #adding the set of parameters to the list\n",
    "  params_list.append({'modality': modality,\n",
    "                      'class': class_type,\n",
    "                      'base_name': base_name, \n",
    "                      'param_grid': {'img_size': img_size, 'num_class': num_class, 'drop_rate': drop_rate, \n",
    "                                    'epochs': n_epochs, 'batch_size': batch_size, \n",
    "                                    'learning_rate':lr0, 'lr_decay_rate': lr_decay_rate, 'lr_min': lr_min,\n",
    "                                    'validation_data': (X_test, y_test), 'callbacks': [callbacks], 'parallel_gpu': False},\n",
    "                      'nfolds_grid': nfolds_grid, 'nfolds_cv': nfolds_cv\n",
    "                    })\n",
    "\n",
    "#Running the batch over params_list\n",
    "results = fit_save_all(params_list, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, result_file_name = result_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check the saved result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>class</th>\n",
       "      <th>vectorization</th>\n",
       "      <th>classifier</th>\n",
       "      <th>tested_params</th>\n",
       "      <th>best_params</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_cv_test</th>\n",
       "      <th>score_cv_train</th>\n",
       "      <th>fit_cv_time</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image</td>\n",
       "      <td>ImgClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VGG16</td>\n",
       "      <td>{'img_size': [(224, 224, 3)], 'num_class': [27...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>image/VGG16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modality          class  vectorization classifier  \\\n",
       "0    image  ImgClassifier            NaN      VGG16   \n",
       "\n",
       "                                       tested_params  best_params  score_test  \\\n",
       "0  {'img_size': [(224, 224, 3)], 'num_class': [27...          NaN    0.443956   \n",
       "\n",
       "   score_cv_test  score_cv_train  fit_cv_time   model_path  \n",
       "0            NaN             NaN          NaN  image/VGG16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_batch_results('results_benchmark_img')\n",
    "display(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
